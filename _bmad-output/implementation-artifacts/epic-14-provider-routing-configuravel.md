# Epic 14: Sistema ConfigurÃ¡vel de Provider Routing (IA Cost Optimization)

**Status:** Backlog
**Created:** 2026-02-14
**Estimated Effort:** 5 stories, ~1.5-2 sprints (~21 pontos)
**Priority:** CRITICAL (impacto direto em margem operacional - economia de 89%)

---

## ğŸ¯ Goal

Implementar sistema de roteamento configurÃ¡vel de providers de IA (STT e LLM) que permite **trocar providers via configuraÃ§Ã£o** (sem code changes) para **reduzir custos operacionais em 89%** (de R$0.93/aula para R$0.27/aula), mantendo qualidade pedagÃ³gica e permitindo A/B testing fÃ¡cil.

---

## ğŸ‘¥ User Outcome

- **Product Owner** pode alterar providers de IA em produÃ§Ã£o apenas mudando `.env` ou `providers.config.json` (zero downtime, zero deploy)
- **Tech Lead** tem visibilidade de custos por provider em dashboard e pode otimizar configuraÃ§Ã£o baseado em dados reais
- **Professor** nÃ£o percebe mudanÃ§a (qualidade mantida) mas custos operacionais caem 89%, aumentando margem do produto
- **Time de Vendas** pode oferecer preÃ§os mais competitivos com margem saudÃ¡vel

---

## ğŸ“‹ FRs Covered

- **Novo:** FR54: Sistema deve suportar mÃºltiplos providers de STT (Groq Whisper, OpenAI Whisper) com roteamento configurÃ¡vel
- **Novo:** FR55: Sistema deve suportar mÃºltiplos providers de LLM (Gemini 2.0 Flash, Claude, GPT-4o mini) com roteamento configurÃ¡vel por tipo de anÃ¡lise
- **Novo:** FR56: Sistema deve ter fallback automÃ¡tico se provider primÃ¡rio falhar
- **Novo:** FR57: Dashboard Admin deve mostrar custos por provider para anÃ¡lise e otimizaÃ§Ã£o
- **Aprimoramento de:** FR18 (transcriÃ§Ã£o de Ã¡udio), FR19 (anÃ¡lise pedagÃ³gica por IA), FR46 (monitoramento de custos)

---

## ğŸ’° Business Impact

### **ROI Projetado**

**Custo Atual (baseline):**
- STT (OpenAI Whisper): $0.30/aula
- LLM (Claude Sonnet 4): $0.186/aula
- **Total: $0.486/aula (~R$2.43 @ R$5/USD)**

**Custo Projetado (otimizado):**
- STT (Groq Whisper Large v3 Turbo): $0.033/aula
- LLM (Gemini 2.0 Flash): $0.014/aula
- LLM (GPT-4o mini - exercÃ­cios): $0.006/aula
- **Total: $0.053/aula (~R$0.27)**

**Economia:** **89%** (R$2.16/aula)

### **Impacto Financeiro**

| Escala | Aulas/MÃªs | Economia Mensal | Economia Anual |
|--------|-----------|-----------------|----------------|
| **1 escola** | 400 | R$864 | R$10.368 |
| **10 escolas** | 4.000 | R$8.640 | R$103.680 |
| **100 escolas** | 40.000 | R$86.400 | **R$1.036.800** |

**ROI do desenvolvimento:**
- Investimento: ~10 dias dev = ~R$8.000
- Payback: **~9 dias** (com 100 escolas) ou **~1 mÃªs** (com 1 escola)

---

## ğŸš€ Key Deliverables

### Backend - Provider Infrastructure
- [ ] `ProviderRouter` service para STT com roteamento configurÃ¡vel
- [ ] `LLMRouter` service para LLM com roteamento por tipo de anÃ¡lise (cobertura, qualitativa, relatÃ³rio, exercÃ­cios, alertas)
- [ ] `GroqWhisperProvider` implementando interface `STTProvider`
- [ ] `GeminiProvider` implementando interface `LLMProvider`
- [ ] Sistema de fallback automÃ¡tico (primary â†’ fallback â†’ error)
- [ ] Hot-reload de configuraÃ§Ã£o (sem restart)

### Configuration Layer
- [ ] Schema de configuraÃ§Ã£o em JSON com validaÃ§Ã£o via Zod
- [ ] Suporte para configuraÃ§Ã£o via `.env` (secrets) + `providers.config.json` (routing logic)
- [ ] Defaults seguros (fallback para providers atuais se config invÃ¡lida)

### Integration & Testing
- [ ] `AnaliseService` e `STTService` integrados com routers
- [ ] Testes E2E: aula completa processada com novo setup
- [ ] ValidaÃ§Ã£o de qualidade: 30 aulas reais processadas com Gemini vs Claude (comparaÃ§Ã£o)

### Monitoring & Analytics
- [ ] Dashboard Admin: custos por provider (breakdown detalhado)
- [ ] Logs estruturados: provider usado, latÃªncia, custo, success/failure
- [ ] Endpoint `/api/v1/admin/analytics/provider-costs` (mÃ©tricas agregadas)

---

## ğŸ“¦ Stories

### **Story 14.1: Camada de Roteamento ConfigurÃ¡vel**
**Complexidade:** M (5 pontos) | **Prioridade:** P0 (blocker)

**User Story:**
> Como desenvolvedor, quero uma camada de roteamento que leia configuraÃ§Ã£o e roteia operaÃ§Ãµes para providers especÃ­ficos, para que o sistema decida em runtime qual provider usar sem code changes.

**Acceptance Criteria:**
- [ ] AC1: `ProviderRouter` service criado para STT com mÃ©todos `getSTTProvider(operation)` e `getSTTFallback()`
- [ ] AC2: `LLMRouter` service criado para LLM com mÃ©todo `getLLMProvider(analysisType: 'cobertura' | 'qualitativa' | 'relatorio' | 'exercicios' | 'alertas')`
- [ ] AC3: Config suporta estrutura:
```typescript
{
  "stt": {
    "primary": "GROQ_WHISPER_TURBO",
    "fallback": "OPENAI_WHISPER"
  },
  "llm": {
    "analise_cobertura": { "primary": "GEMINI_FLASH", "fallback": "CLAUDE_SONNET" },
    "analise_qualitativa": { "primary": "GEMINI_FLASH", "fallback": "CLAUDE_SONNET" },
    "relatorio": { "primary": "GEMINI_FLASH", "fallback": "GPT4_MINI" },
    "exercicios": { "primary": "GPT4_MINI", "fallback": "GEMINI_FLASH" },
    "alertas": { "primary": "GEMINI_FLASH", "fallback": "CLAUDE_SONNET" }
  }
}
```
- [ ] AC4: Router tenta primary â†’ se falhar, tenta fallback â†’ se falhar, throw error com contexto claro
- [ ] AC5: Logs estruturados (Pino) registram: provider tentado, fallback usado (se aplicÃ¡vel), latÃªncia, custo, success/failure
- [ ] AC6: Suporta hot-reload de config via `ConfigService.watch()` (sem restart do servidor)
- [ ] AC7: ValidaÃ§Ã£o de schema via Zod com mensagens de erro claras
- [ ] AC8: Defaults seguros: se config invÃ¡lida ou ausente, usa providers atuais (OpenAI Whisper + Claude)
- [ ] AC9: Testes unitÃ¡rios: mock providers, validaÃ§Ã£o de roteamento, fallback behavior, config invÃ¡lida
- [ ] AC10: Cobertura de testes â‰¥85%

**Arquivos:**
- `src/modules/stt/services/stt-router.service.ts` (novo)
- `src/modules/stt/services/stt-router.service.spec.ts` (novo)
- `src/modules/llm/services/llm-router.service.ts` (novo)
- `src/modules/llm/services/llm-router.service.spec.ts` (novo)
- `src/config/providers.config.ts` (novo - schema Zod + loader)
- `src/config/providers.config.spec.ts` (novo)

**Technical Notes:**
- Router usa Dependency Injection (NestJS) para obter providers
- Config loader usa `ConfigService` do NestJS
- Fallback logic com retry exponential backoff (3 tentativas, 1s â†’ 2s â†’ 4s)

---

### **Story 14.2: Implementar Groq Whisper Provider (STT)**
**Complexidade:** S (3 pontos) | **Prioridade:** P0

**User Story:**
> Como sistema, quero suporte para Groq Whisper Large v3 Turbo, para que possa reduzir custo de STT em 89% ($0.36 â†’ $0.04/hora) mantendo qualidade.

**Acceptance Criteria:**
- [ ] AC1: `GroqWhisperProvider` criado implementando interface `STTProvider`
- [ ] AC2: Suporta 3 modelos Groq via env var `GROQ_WHISPER_MODEL`:
  - `whisper-large-v3-turbo` ($0.04/hora) - primÃ¡rio
  - `distil-whisper` ($0.02/hora) - ultra barato
  - `whisper-large-v3` ($0.111/hora) - mÃ¡xima qualidade
- [ ] AC3: Provider calcula custo real baseado em: `(duration_minutes / 60) * COST_PER_HOUR`
- [ ] AC4: Retorna `TranscriptionResult` normalizado (compatÃ­vel com `WhisperSTTService`)
- [ ] AC5: Logs estruturados incluem: modelo usado, tempo processamento (ms), custo (USD), confidence score
- [ ] AC6: Error handling: timeout (300s), rate limit (retry 3x), API errors (mensagens claras)
- [ ] AC7: Testes unitÃ¡rios: mock Groq API, validaÃ§Ã£o de output, cÃ¡lculo de custo, error handling
- [ ] AC8: Teste E2E: processa 1 Ã¡udio real de 50min e valida:
  - TranscriÃ§Ã£o retornada
  - Confidence â‰¥0.85
  - Custo calculado correto (~$0.033)
  - Tempo processamento <60s
- [ ] AC9: Health check via `isAvailable()` method
- [ ] AC10: Cobertura de testes â‰¥85%

**Arquivos:**
- `src/modules/stt/providers/groq-whisper.provider.ts` (novo)
- `src/modules/stt/providers/groq-whisper.provider.spec.ts` (novo)
- `test/stt/groq-whisper-provider.e2e-spec.ts` (novo)

**VariÃ¡veis de ambiente:**
```bash
# .env
GROQ_API_KEY=gsk_...
GROQ_WHISPER_MODEL=whisper-large-v3-turbo  # ou distil-whisper, whisper-large-v3
```

**DependÃªncias:**
```json
{
  "groq-sdk": "^0.7.0"
}
```

**Technical Notes:**
- Groq API Ã© compatÃ­vel com OpenAI Whisper API (facilitaÃ§Ã£o migraÃ§Ã£o)
- Rate limit Groq: 30 requests/min (menor que OpenAI 50 RPM) - considerar queue
- Pricing Groq: $0.04/hora (Turbo), $0.02/hora (Distil), $0.111/hora (Large v3)

---

### **Story 14.3: Implementar Gemini 2.0 Flash Provider (LLM)**
**Complexidade:** M (5 pontos) | **Prioridade:** P0

**User Story:**
> Como sistema, quero suporte para Google Gemini 2.0 Flash, para que possa reduzir custo de anÃ¡lise pedagÃ³gica em 92% ($0.18 â†’ $0.014/aula) mantendo qualidade.

**Acceptance Criteria:**
- [ ] AC1: `GeminiProvider` criado implementando interface `LLMProvider`
- [ ] AC2: Suporta modelo `gemini-2.0-flash-001` via env var `GEMINI_MODEL`
- [ ] AC3: Provider calcula custo real:
  - Input: `(tokens_input / 1_000_000) * 0.10` USD
  - Output: `(tokens_output / 1_000_000) * 0.40` USD
- [ ] AC4: Retorna `LLMResult` normalizado (compatÃ­vel com `ClaudeProvider`)
- [ ] AC5: Suporta context window de atÃ© 1M tokens
- [ ] AC6: Suporta `systemPrompt` configurÃ¡vel (igual Claude/GPT)
- [ ] AC7: Logs estruturados incluem: modelo usado, tokens (input/output), custo (USD), latÃªncia (ms), stop_reason
- [ ] AC8: Error handling: timeout (120s), rate limit (retry 3x exponential backoff), API errors, safety filters (se Gemini bloquear por safety)
- [ ] AC9: Testes unitÃ¡rios: mock Google AI API, validaÃ§Ã£o JSON output, cÃ¡lculo de custo, error handling
- [ ] AC10: Teste E2E: executa Prompt 1 (Cobertura BNCC) com transcriÃ§Ã£o real de 50min e valida:
  - Output JSON vÃ¡lido (schema Prompt 1)
  - Habilidades detectadas â‰¥1
  - Custo calculado ~$0.014
  - Tempo processamento <30s

**Arquivos:**
- `src/modules/llm/providers/gemini.provider.ts` (novo)
- `src/modules/llm/providers/gemini.provider.spec.ts` (novo)
- `test/llm/gemini-provider.e2e-spec.ts` (novo)

**VariÃ¡veis de ambiente:**
```bash
# .env
GOOGLE_AI_API_KEY=AIza...
GEMINI_MODEL=gemini-2.0-flash-001
```

**DependÃªncias:**
```json
{
  "@google/generative-ai": "^0.21.0"
}
```

**Technical Notes:**
- Google Generative AI SDK usa streaming por padrÃ£o - desabilitar para obter output completo
- Gemini tem safety filters que podem bloquear output - implementar handling
- Rate limit Gemini: 360 RPM (muito maior que Claude 50 RPM)
- Pricing Gemini: $0.10/1M input, $0.40/1M output

---

### **Story 14.4: IntegraÃ§Ã£o do Router com Pipeline de AnÃ¡lise**
**Complexidade:** M (5 pontos) | **Prioridade:** P0

**User Story:**
> Como pipeline de anÃ¡lise, quero usar o ProviderRouter para selecionar providers dinamicamente, para que cada prompt use o provider configurado em `providers.config.json` sem code changes.

**Acceptance Criteria:**
- [ ] AC1: `AnaliseService` refatorado para usar `LLMRouter.getLLMProvider(analysisType)` em vez de chamar `ClaudeProvider` diretamente
- [ ] AC2: `STTService` refatorado para usar `STTRouter.getSTTProvider()` em vez de chamar `WhisperSTTService` diretamente
- [ ] AC3: Config padrÃ£o criado em `providers.config.json` (raiz do projeto):
```json
{
  "version": "1.0.0",
  "stt": {
    "primary": "GROQ_WHISPER_TURBO",
    "fallback": "OPENAI_WHISPER"
  },
  "llm": {
    "analise_cobertura": { "primary": "GEMINI_FLASH", "fallback": "CLAUDE_SONNET" },
    "analise_qualitativa": { "primary": "GEMINI_FLASH", "fallback": "CLAUDE_SONNET" },
    "relatorio": { "primary": "GEMINI_FLASH", "fallback": "GPT4_MINI" },
    "exercicios": { "primary": "GPT4_MINI", "fallback": "GEMINI_FLASH" },
    "alertas": { "primary": "GEMINI_FLASH", "fallback": "CLAUDE_SONNET" }
  }
}
```
- [ ] AC4: Se provider primÃ¡rio falhar (timeout, API error), sistema automaticamente tenta fallback
- [ ] AC5: Logs mostram claramente: provider primÃ¡rio tentado, fallback usado (se aplicÃ¡vel), custo total da operaÃ§Ã£o
- [ ] AC6: AnÃ¡lise completa (5 prompts) registra breakdown de custos:
```typescript
{
  "analise_id": "uuid",
  "custos": {
    "stt": { "provider": "GROQ_WHISPER_TURBO", "custo_usd": 0.033 },
    "llm_cobertura": { "provider": "GEMINI_FLASH", "custo_usd": 0.0035 },
    "llm_qualitativa": { "provider": "GEMINI_FLASH", "custo_usd": 0.0035 },
    "llm_relatorio": { "provider": "GEMINI_FLASH", "custo_usd": 0.0035 },
    "llm_exercicios": { "provider": "GPT4_MINI", "custo_usd": 0.006 },
    "llm_alertas": { "provider": "GEMINI_FLASH", "custo_usd": 0.0035 },
    "total_usd": 0.053
  }
}
```
- [ ] AC7: Testes E2E: processa 1 aula completa (upload Ã¡udio â†’ STT â†’ 5 prompts LLM) com novo setup e valida:
  - AnÃ¡lise completa bem-sucedida
  - Providers corretos usados conforme config
  - Custo total ~$0.053
  - Output JSON vÃ¡lido em todos os 5 prompts
- [ ] AC8: Fallback testado: forÃ§ar falha de provider primÃ¡rio e validar que fallback Ã© usado
- [ ] AC9: Compatibilidade backward: providers antigos (OpenAI Whisper + Claude) continuam funcionando
- [ ] AC10: DocumentaÃ§Ã£o atualizada: README com instruÃ§Ãµes de configuraÃ§Ã£o de providers

**Arquivos afetados:**
- `src/modules/analise/services/analise.service.ts`
- `src/modules/analise/services/analise.service.spec.ts`
- `src/modules/stt/stt.service.ts`
- `src/modules/stt/stt.service.spec.ts`
- `providers.config.json` (novo - raiz do projeto)
- `test/analise-pipeline-routed.e2e-spec.ts` (novo)
- `README.md` (atualizar seÃ§Ã£o de configuraÃ§Ã£o)

**Technical Notes:**
- Router injection via NestJS DI (constructor injection)
- Config loader usa singleton pattern (cache de config)
- Logs devem incluir `analysis_id` para rastreabilidade

---

### **Story 14.5: Dashboard de Custos por Provider**
**Complexidade:** S (3 pontos) | **Prioridade:** P1 (nice-to-have)

**User Story:**
> Como Product Owner, quero ver em dashboard quanto cada provider estÃ¡ custando, para que possa validar economia real e ajustar configuraÃ§Ã£o baseado em dados.

**Acceptance Criteria:**
- [ ] AC1: Endpoint `GET /api/v1/admin/analytics/provider-costs` criado (apenas Admin)
- [ ] AC2: Query params: `?period=last_7_days|last_30_days|last_90_days` (default: `last_30_days`)
- [ ] AC3: Retorna breakdown por provider:
```json
{
  "period": "last_30_days",
  "total_cost_usd": 21.50,
  "total_operations": 400,
  "avg_cost_per_operation": 0.0538,
  "by_provider": [
    {
      "provider": "GROQ_WHISPER_TURBO",
      "type": "STT",
      "operations": 400,
      "total_cost_usd": 13.20,
      "avg_cost_per_operation": 0.033,
      "avg_latency_ms": 8500
    },
    {
      "provider": "GEMINI_FLASH",
      "type": "LLM",
      "operations": 1600,
      "total_cost_usd": 22.40,
      "avg_cost_per_operation": 0.014,
      "avg_latency_ms": 4200
    },
    {
      "provider": "GPT4_MINI",
      "type": "LLM",
      "operations": 400,
      "total_cost_usd": 2.40,
      "avg_cost_per_operation": 0.006,
      "avg_latency_ms": 3100
    }
  ],
  "savings_vs_baseline": {
    "baseline_provider": "CLAUDE_SONNET + OPENAI_WHISPER",
    "baseline_cost_usd": 194.40,
    "current_cost_usd": 38.00,
    "savings_usd": 156.40,
    "savings_percent": 80.45
  }
}
```
- [ ] AC4: Dados agregados de tabela `Analise` (campos: `custo_stt_usd`, `custo_llm_usd`, `provider_stt`, `provider_llm_*`)
- [ ] AC5: RBAC guard: apenas usuÃ¡rios com role `ADMIN` podem acessar
- [ ] AC6: Swagger docs: endpoint documentado com exemplo de response
- [ ] AC7: Testes unitÃ¡rios: mock repository, validaÃ§Ã£o de agregaÃ§Ã£o, cÃ¡lculo de savings
- [ ] AC8: Teste E2E: processar 5 aulas â†’ chamar endpoint â†’ validar custos corretos
- [ ] AC9: Performance: query otimizada com Ã­ndices em `created_at` e `provider_*`
- [ ] AC10: Frontend dashboard (opcional - pode ser Story futura): grÃ¡fico de custos por provider (recharts)

**Arquivos:**
- `src/modules/admin/admin.controller.ts` (adicionar endpoint)
- `src/modules/admin/services/provider-analytics.service.ts` (novo)
- `src/modules/admin/services/provider-analytics.service.spec.ts` (novo)
- `src/modules/admin/dto/provider-costs-response.dto.ts` (novo)
- `test/admin-provider-costs.e2e-spec.ts` (novo)

**Technical Notes:**
- Query usa agregaÃ§Ã£o SQL: `GROUP BY provider, SUM(custo_usd), AVG(tempo_processamento_ms)`
- Ãndices necessÃ¡rios: `CREATE INDEX idx_analise_created_at_provider ON Analise(created_at, provider_stt, provider_llm_cobertura)`
- Baseline cost calculado via config hardcoded (Claude: $0.18, OpenAI Whisper: $0.36)

---

## ğŸ”§ Technical Architecture

### **Provider Routing Flow**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REQUEST: Processar Aula                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   AnaliseService         â”‚
                â”‚   (Orchestrator)         â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                  â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ STTRouter  â”‚    â”‚ LLMRouter  â”‚    â”‚ LLMRouter  â”‚
    â”‚            â”‚    â”‚ (Prompt 1) â”‚    â”‚ (Prompt 2) â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                  â”‚
          â”‚ reads config    â”‚ reads config     â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚         providers.config.json                    â”‚
    â”‚  {                                               â”‚
    â”‚    "stt": { "primary": "GROQ_WHISPER_TURBO" },  â”‚
    â”‚    "llm": {                                      â”‚
    â”‚      "analise_cobertura": { "primary": "GEMINI" }â”‚
    â”‚    }                                             â”‚
    â”‚  }                                               â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ Groq       â”‚    â”‚ Gemini     â”‚    â”‚ Gemini     â”‚
    â”‚ Provider   â”‚    â”‚ Provider   â”‚    â”‚ Provider   â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                  â”‚
          â”‚ API call        â”‚ API call         â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ Groq API   â”‚    â”‚ Google AI  â”‚    â”‚ Google AI  â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Logs + Metrics  â”‚
                    â”‚  (Pino + Prisma) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Fallback Logic**

```typescript
// STTRouter.getSTTProvider()
async getSTTProvider(): Promise<STTProvider> {
  const config = this.configService.get('stt');

  try {
    const primary = this.getPrimaryProvider(config.primary);
    if (await primary.isAvailable()) {
      this.logger.log(`Using primary STT provider: ${config.primary}`);
      return primary;
    }
  } catch (error) {
    this.logger.warn(`Primary STT provider failed: ${error.message}`);
  }

  // Fallback
  try {
    const fallback = this.getFallbackProvider(config.fallback);
    this.logger.warn(`Using fallback STT provider: ${config.fallback}`);
    return fallback;
  } catch (error) {
    this.logger.error(`Fallback STT provider failed: ${error.message}`);
    throw new Error('All STT providers unavailable');
  }
}
```

### **Config Schema (Zod Validation)**

```typescript
// src/config/providers.config.ts
import { z } from 'zod';

const ProviderEnum = z.enum([
  'GROQ_WHISPER_TURBO',
  'GROQ_DISTIL_WHISPER',
  'GROQ_WHISPER_LARGE',
  'OPENAI_WHISPER',
  'GEMINI_FLASH',
  'CLAUDE_SONNET',
  'GPT4_MINI',
]);

const STTConfigSchema = z.object({
  primary: ProviderEnum,
  fallback: ProviderEnum,
});

const LLMAnalysisConfigSchema = z.object({
  primary: ProviderEnum,
  fallback: ProviderEnum,
});

export const ProvidersConfigSchema = z.object({
  version: z.string(),
  stt: STTConfigSchema,
  llm: z.object({
    analise_cobertura: LLMAnalysisConfigSchema,
    analise_qualitativa: LLMAnalysisConfigSchema,
    relatorio: LLMAnalysisConfigSchema,
    exercicios: LLMAnalysisConfigSchema,
    alertas: LLMAnalysisConfigSchema,
  }),
});

export type ProvidersConfig = z.infer<typeof ProvidersConfigSchema>;
```

---

## âš ï¸ Risks & Mitigations

| Risco | Prob | Impacto | MitigaÃ§Ã£o |
|-------|------|---------|-----------|
| **Gemini gera relatÃ³rios piores que Claude** | M | Alto | POC com 30 aulas reais antes de produÃ§Ã£o + fallback automÃ¡tico para Claude |
| **Groq Whisper tem WER maior em PT-BR** | M | MÃ©dio | Testar com 10 Ã¡udios reais diversos (ruÃ­do alto, sotaques) + fallback para OpenAI |
| **Rate limits Groq/Gemini** | B | MÃ©dio | Implementar retry com exponential backoff + fallback + queue system (Bull) |
| **Config invÃ¡lida quebra sistema** | B | Alto | ValidaÃ§Ã£o de schema Zod + defaults seguros (fallback para providers atuais) |
| **Groq/Gemini downtime** | B | MÃ©dio | Fallback automÃ¡tico para OpenAI/Claude + logs + alertas |
| **MigraÃ§Ã£o quebra pipeline existente** | M | CrÃ­tico | Testes E2E extensivos + rollout gradual (10% â†’ 50% â†’ 100%) + flag de feature |

---

## ğŸ“‹ Testing Strategy

### **Unit Tests**
- Routers: validaÃ§Ã£o de roteamento, fallback logic, config invÃ¡lida
- Providers: mock APIs, validaÃ§Ã£o de output, cÃ¡lculo de custo
- Config loader: schema validation, defaults, hot-reload

### **E2E Tests**
- Pipeline completo: 1 aula (upload â†’ STT â†’ 5 prompts LLM)
- Fallback: forÃ§ar falha de provider primÃ¡rio
- Multi-provider: processar 3 aulas com configs diferentes

### **Quality Validation (POC)**
- Processar 30 aulas reais com:
  - Config A: Claude + OpenAI Whisper (baseline)
  - Config B: Gemini + Groq Whisper (otimizado)
- Comparar mÃ©tricas:
  - Taxa de aprovaÃ§Ã£o de relatÃ³rios
  - Tempo de revisÃ£o por professor
  - WER (Word Error Rate) de transcriÃ§Ãµes
  - NPS (se possÃ­vel coletar)

### **Performance Tests**
- LatÃªncia: validar que Groq/Gemini nÃ£o adicionam latÃªncia significativa
- Throughput: processar 50 aulas em paralelo (stress test)

---

## ğŸ“Š Success Metrics

### **MÃ©tricas de NegÃ³cio (90 dias apÃ³s rollout)**
- [ ] Custo mÃ©dio por aula â‰¤ R$0.30 (economia â‰¥85%)
- [ ] Economia total acumulada â‰¥ R$20.000 (assumindo 10 escolas)
- [ ] Taxa de aprovaÃ§Ã£o de relatÃ³rios â‰¥ 80% (mantida vs baseline Claude)

### **MÃ©tricas TÃ©cnicas**
- [ ] Uptime de providers â‰¥ 99.5% (combinado primary + fallback)
- [ ] LatÃªncia mÃ©dia STT â‰¤ 60s (para 50min de Ã¡udio)
- [ ] LatÃªncia mÃ©dia LLM â‰¤ 30s (por prompt)
- [ ] Taxa de fallback â‰¤ 5% (indica alta disponibilidade de providers primÃ¡rios)

### **MÃ©tricas de Qualidade**
- [ ] WER (Word Error Rate) Groq â‰¤ 15% (validado com 30 Ã¡udios)
- [ ] Taxa de aprovaÃ§Ã£o de relatÃ³rios Gemini â‰¥ 75% (comparado a Claude 80%)
- [ ] Tempo de revisÃ£o de relatÃ³rios â‰¤ 5min (mantido)

---

## ğŸš€ Rollout Plan

### **Fase 1: Development & Testing (Semana 1-2)**
- Implementar Stories 14.1, 14.2, 14.3
- Testes unitÃ¡rios + E2E
- POC com 30 aulas reais (validaÃ§Ã£o de qualidade)

### **Fase 2: Integration (Semana 2-3)**
- Implementar Story 14.4 (integraÃ§Ã£o com pipeline)
- Testes E2E completos
- Configurar `providers.config.json` padrÃ£o

### **Fase 3: Monitoring (Semana 3-4)**
- Implementar Story 14.5 (dashboard de custos)
- Configurar alertas (Sentry + logs)
- DocumentaÃ§Ã£o completa

### **Fase 4: Gradual Rollout (Semana 4-6)**
- **Semana 4:** 10% das escolas (1-2 escolas piloto)
- **Semana 5:** 50% das escolas (monitorar mÃ©tricas)
- **Semana 6:** 100% das escolas (se mÃ©tricas OK)

**CritÃ©rios para avanÃ§ar fases:**
- Taxa de aprovaÃ§Ã£o â‰¥ 75%
- Taxa de fallback â‰¤ 10%
- Nenhum erro crÃ­tico reportado

**Rollback plan:**
- Se mÃ©tricas crÃ­ticas falharem: reverter config para providers antigos (1 linha de mudanÃ§a em `providers.config.json`)
- Zero downtime (hot-reload de config)

---

## ğŸ“š Documentation

### **User-Facing**
- [ ] README.md: instruÃ§Ãµes de configuraÃ§Ã£o de providers
- [ ] Admin guide: como interpretar dashboard de custos

### **Developer-Facing**
- [ ] Architecture Decision Record (ADR): Provider Routing Strategy
- [ ] API docs: endpoint `/api/v1/admin/analytics/provider-costs` (Swagger)
- [ ] Migration guide: como adicionar novo provider no futuro

### **Operations**
- [ ] Runbook: troubleshooting provider failures
- [ ] Monitoring setup: dashboards + alertas (Sentry)

---

## ğŸ¯ Definition of Done (Epic Level)

- [ ] Todas as 5 stories completadas e code review aprovado
- [ ] Testes E2E passando (coverage â‰¥85%)
- [ ] POC validado: 30 aulas processadas com Gemini/Groq com qualidade aceitÃ¡vel
- [ ] Dashboard de custos mostrando economia real
- [ ] DocumentaÃ§Ã£o completa (README + ADR + Runbook)
- [ ] Rollout gradual completo (100% escolas usando novos providers)
- [ ] Economia de custos â‰¥85% validada em produÃ§Ã£o

---

## ğŸ“… Timeline

| Fase | DuraÃ§Ã£o | EntregÃ¡vel |
|------|---------|------------|
| **Sprint 1 (Semanas 1-2)** | 10 dias | Stories 14.1, 14.2, 14.3 + POC |
| **Sprint 2 (Semanas 3-4)** | 10 dias | Stories 14.4, 14.5 + Docs + Rollout 10% |
| **ConsolidaÃ§Ã£o (Semanas 5-6)** | 10 dias | Rollout 50% â†’ 100% + ValidaÃ§Ã£o |
| **TOTAL** | **~30 dias** | Epic completo + economia validada |

---

## ğŸ”— Related Epics

- **Epic 4:** TranscriÃ§Ã£o de Ãudio (STT) - base para Story 14.2
- **Epic 5:** AnÃ¡lise PedagÃ³gica por IA (LLM) - base para Story 14.3
- **Epic 8:** Monitoramento e Observabilidade - base para Story 14.5

---

**Created by:** Luisneto98
**Reviewed by:** -
**Last Updated:** 2026-02-14
