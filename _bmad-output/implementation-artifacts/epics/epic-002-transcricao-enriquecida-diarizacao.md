# ğŸ“¦ Ã‰PICO 002: TranscriÃ§Ã£o Enriquecida com DiarizaÃ§Ã£o via LLM

**Projeto:** Ressoa AI (Professor Analytics)
**Data de CriaÃ§Ã£o:** 2026-02-15
**VersÃ£o:** 1.0
**Status:** ğŸ“‹ Planejado
**Prioridade:** **P1 - ALTO VALOR**

---

## ğŸ“Œ VisÃ£o Geral

**ID:** EPIC-002
**TÃ­tulo:** Pipeline de TranscriÃ§Ã£o Enriquecida com Timestamps por Palavra, Prompt PedagÃ³gico e DiarizaÃ§Ã£o Professor/Aluno via LLM
**ResponsÃ¡vel:** Dev Team
**Estimativa:** 8-12 dias de desenvolvimento

### Problema a Resolver

A transcriÃ§Ã£o atual Ã© "crua": texto corrido sem marcaÃ§Ã£o temporal por palavra e sem identificaÃ§Ã£o de quem falou (professor vs aluno). Isso limita severamente a qualidade da anÃ¡lise pedagÃ³gica downstream:

- A IA nÃ£o sabe **quem disse o quÃª** â€” nÃ£o consegue diferenciar explicaÃ§Ãµes do professor de respostas/perguntas dos alunos
- Sem timestamps granulares, a IA nÃ£o consegue correlacionar **momentos da aula** com conteÃºdos especÃ­ficos
- Sem prompt de contexto, o STT erra termos pedagÃ³gicos e cÃ³digos BNCC (ex: "EF06MA01" transcrito como "Ã© Ã©fe zero seis eme a zero um")
- O pipeline de 5 prompts (MOAT tÃ©cnico) recebe entrada de baixa qualidade, degradando todas as anÃ¡lises subsequentes

### SoluÃ§Ã£o Proposta

Pipeline de enriquecimento em 3 etapas:

1. **STT com Prompt + Word Timestamps** â€” Enviar vocabulÃ¡rio pedagÃ³gico/BNCC como `prompt` e ativar `timestamp_granularities: ["word"]` nos providers Whisper e Groq
2. **DiarizaÃ§Ã£o via LLM** â€” Passar a transcriÃ§Ã£o com timestamps por palavra para um LLM leve (Gemini Flash, configurÃ¡vel) que identifica `PROFESSOR` vs `ALUNO` por contexto linguÃ­stico
3. **SaÃ­da em SRT com Speaker Labels** â€” Salvar no campo `texto` da `Transcricao` em formato SRT enriquecido que os prÃ³ximos LLMs do pipeline conseguem interpretar nativamente

### Valor de NegÃ³cio

- âœ… **Qualidade da anÃ¡lise pedagÃ³gica** â€” LLMs downstream sabem quem falou o quÃª e quando
- âœ… **MÃ©tricas de participaÃ§Ã£o** â€” Tempo de fala professor vs alunos, frequÃªncia de interaÃ§Ãµes
- âœ… **AcurÃ¡cia da transcriÃ§Ã£o** â€” Prompt com vocabulÃ¡rio BNCC reduz erros em termos tÃ©cnicos
- âœ… **Contexto temporal** â€” CorrelaÃ§Ã£o entre momentos da aula e habilidades trabalhadas
- âœ… **Diferencial competitivo** â€” ReforÃ§a o MOAT tÃ©cnico (nenhum concorrente oferece anÃ¡lise com diarizaÃ§Ã£o)
- âœ… **Custo otimizado** â€” Gemini Flash para diarizaÃ§Ã£o (~$0.01/aula) vs APIs dedicadas de diarizaÃ§Ã£o (~$0.10+/aula)

### Exemplo de SaÃ­da (SRT Enriquecido)

```srt
1
00:00:01,200 --> 00:00:05,800
[PROFESSOR] Bom dia, turma! Hoje vamos trabalhar com fraÃ§Ãµes equivalentes, habilidade EF06MA01.

2
00:00:06,100 --> 00:00:08,400
[ALUNO] Professor, fraÃ§Ãµes equivalentes Ã© aquilo de pizza?

3
00:00:08,800 --> 00:00:15,200
[PROFESSOR] Exatamente! Vamos comeÃ§ar com exemplos visuais. Quando cortamos uma pizza em 4 pedaÃ§os e comemos 2...

4
00:00:15,500 --> 00:00:17,100
[ALUNO] Ã‰ metade!

5
00:00:17,300 --> 00:00:25,600
[PROFESSOR] Isso! Dois quartos Ã© igual a um meio. Essa Ã© a ideia de equivalÃªncia. Vamos ver mais exemplos no quadro.
```

---

## ğŸ—ï¸ Arquitetura e DecisÃµes TÃ©cnicas

### Fluxo do Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ãudio da Aula      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STT (Whisper/Groq)                     â”‚
â”‚  + prompt: vocabulÃ¡rio pedagÃ³gico       â”‚
â”‚  + timestamp_granularities: ["word"]    â”‚
â”‚  â†’ JSON com palavras + timestamps       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM DiarizaÃ§Ã£o (Gemini Flash)          â”‚
â”‚  + TranscriÃ§Ã£o word-level               â”‚
â”‚  + Prompt de diarizaÃ§Ã£o                 â”‚
â”‚  â†’ SRT com [PROFESSOR] / [ALUNO]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Salvar no banco (campo texto)          â”‚
â”‚  formato: SRT enriquecido               â”‚
â”‚  â†’ Input para pipeline de 5 prompts     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### DecisÃµes TÃ©cnicas

| DecisÃ£o | Escolha | Justificativa |
|---------|---------|---------------|
| Timestamps | Word-level (`timestamp_granularities: ["word"]`) | Granularidade mÃ¡xima para diarizaÃ§Ã£o precisa |
| LLM para diarizaÃ§Ã£o | Gemini Flash (configurÃ¡vel via router) | Custo baixÃ­ssimo (~$0.01/aula), velocidade, jÃ¡ integrado (Story 14.3) |
| Formato de saÃ­da | SRT com speaker labels | Formato padrÃ£o que LLMs entendem nativamente, inclui timing |
| Armazenamento | Substituir campo `texto` existente | Formato SRT Ã© superset do texto puro â€” LLMs conseguem ler ambos |
| Prompt STT | VocabulÃ¡rio estÃ¡tico por disciplina | Termos BNCC + pedagÃ³gicos que o STT erra frequentemente |
| Fallback | Se diarizaÃ§Ã£o falhar, salvar SRT sem speakers | Garante que a transcriÃ§Ã£o nunca Ã© bloqueada pela diarizaÃ§Ã£o |

### AlteraÃ§Ãµes no Banco de Dados

**Nenhuma migraÃ§Ã£o necessÃ¡ria.** O campo `texto` (`@db.Text`) na model `Transcricao` jÃ¡ suporta conteÃºdo SRT. O `metadata_json` armazenarÃ¡ dados adicionais do processo de diarizaÃ§Ã£o.

Campos utilizados:
- `texto` â€” Passa a conter SRT enriquecido (antes: texto puro)
- `metadata_json` â€” Adiciona: `{ diarization_provider, diarization_cost_usd, diarization_processing_ms, word_count, speaker_segments: { professor: N, aluno: N } }`

---

## ğŸ“‹ User Stories

### ğŸ”µ US-015.1: Adicionar Prompt de Contexto PedagÃ³gico ao STT

**Como** sistema de transcriÃ§Ã£o
**Quero** enviar um prompt com vocabulÃ¡rio pedagÃ³gico/BNCC ao STT
**Para** melhorar a acurÃ¡cia na transcriÃ§Ã£o de termos tÃ©cnicos educacionais

#### Detalhes TÃ©cnicos

O parÃ¢metro `prompt` do Whisper/Groq aceita atÃ© 224 tokens (~800 caracteres) para fornecer contexto vocabular. NÃ£o Ã© uma instruÃ§Ã£o â€” Ã© uma lista de termos que o modelo usa para calibrar a transcriÃ§Ã£o.

#### ImplementaÃ§Ã£o

**Arquivos a modificar:**
- `ressoa-backend/src/modules/stt/providers/whisper.provider.ts`
- `ressoa-backend/src/modules/stt/providers/groq-whisper.provider.ts`

**Prompt por disciplina (exemplos):**

```typescript
const STT_PROMPTS: Record<string, string> = {
  matematica: `FraÃ§Ãµes, equaÃ§Ãµes, Ã¡lgebra, geometria, probabilidade, estatÃ­stica.
Habilidades BNCC: EF06MA01, EF07MA02, EF08MA03, EF09MA04.
Termos: mÃ­nimo mÃºltiplo comum, mÃ¡ximo divisor comum, plano cartesiano,
nÃºmeros racionais, expressÃµes algÃ©bricas, teorema de PitÃ¡goras.`,

  lingua_portuguesa: `GÃªneros textuais, coesÃ£o, coerÃªncia, morfossintaxe, semÃ¢ntica.
Habilidades BNCC: EF67LP01, EF69LP03, EF89LP05.
Termos: substantivo, adjetivo, advÃ©rbio, conjunÃ§Ã£o, oraÃ§Ã£o subordinada,
figuras de linguagem, dissertaÃ§Ã£o argumentativa, crÃ´nica, resenha.`,

  ciencias: `Ecossistema, cÃ©lula, Ã¡tomo, molÃ©cula, energia, fotossÃ­ntese.
Habilidades BNCC: EF06CI01, EF07CI02, EF08CI03, EF09CI04.
Termos: sistema digestÃ³rio, cadeia alimentar, tabela periÃ³dica,
reaÃ§Ã£o quÃ­mica, gravitaÃ§Ã£o, eletromagnetismo, camada de ozÃ´nio.`,
};
```

**CÃ³digo â€” Whisper Provider (adicionar `prompt`):**

```typescript
const response = await this.openai.audio.transcriptions.create({
  file: fs.createReadStream(tempFilePath),
  model: 'whisper-1',
  language: idioma,
  response_format: 'verbose_json',
  prompt: sttPrompt, // NOVO: contexto pedagÃ³gico
});
```

#### CritÃ©rios de AceitaÃ§Ã£o

- [ ] Whisper provider aceita parÃ¢metro `prompt` opcional na chamada de transcriÃ§Ã£o
- [ ] Groq Whisper provider aceita parÃ¢metro `prompt` opcional na chamada de transcriÃ§Ã£o
- [ ] Prompt de vocabulÃ¡rio Ã© selecionado com base na disciplina da aula (via `Planejamento` â†’ `Disciplina`)
- [ ] Prompt default (genÃ©rico) usado quando disciplina nÃ£o estÃ¡ disponÃ­vel
- [ ] Prompt nÃ£o excede 224 tokens (~800 chars) â€” validado em build time
- [ ] Sem regressÃ£o nos testes existentes de transcriÃ§Ã£o
- [ ] Log do prompt utilizado no metadata da transcriÃ§Ã£o

---

### ğŸ”µ US-015.2: Ativar Timestamps por Palavra no STT

**Como** sistema de transcriÃ§Ã£o
**Quero** receber timestamps no nÃ­vel de cada palavra (nÃ£o apenas segmento)
**Para** fornecer granularidade temporal precisa Ã  etapa de diarizaÃ§Ã£o

#### Detalhes TÃ©cnicos

Ambas as APIs (OpenAI Whisper e Groq) suportam o parÃ¢metro `timestamp_granularities` que aceita `["word"]`, `["segment"]` ou `["word", "segment"]`. Quando ativado com `verbose_json`, a resposta inclui um array `words[]` com `{ word, start, end }` para cada palavra.

#### ImplementaÃ§Ã£o

**Arquivos a modificar:**
- `ressoa-backend/src/modules/stt/providers/whisper.provider.ts`
- `ressoa-backend/src/modules/stt/providers/groq-whisper.provider.ts`
- `ressoa-backend/src/modules/stt/interfaces/stt-provider.interface.ts`

**CÃ³digo â€” Whisper Provider:**

```typescript
const response = await this.openai.audio.transcriptions.create({
  file: fs.createReadStream(tempFilePath),
  model: 'whisper-1',
  language: idioma,
  response_format: 'verbose_json',
  prompt: sttPrompt,
  timestamp_granularities: ['word', 'segment'], // NOVO
});
```

**Interface TranscriptionResult â€” Adicionar campo `words`:**

```typescript
export interface TranscriptionWord {
  word: string;
  start: number; // segundos
  end: number;   // segundos
}

export interface TranscriptionResult {
  texto: string;
  words?: TranscriptionWord[]; // NOVO: timestamps por palavra
  provider: ProviderSTT;
  idioma: string;
  duracao_segundos?: number;
  confianca?: number;
  custo_usd: number;
  tempo_processamento_ms: number;
  metadata?: Record<string, any>;
}
```

#### CritÃ©rios de AceitaÃ§Ã£o

- [ ] Whisper provider solicita `timestamp_granularities: ['word', 'segment']`
- [ ] Groq Whisper provider solicita `timestamp_granularities: ['word', 'segment']`
- [ ] `TranscriptionResult` inclui array `words` com `{ word, start, end }` por palavra
- [ ] Array `words` Ã© populado corretamente pelos dois providers
- [ ] Campo `texto` continua sendo preenchido normalmente (compatibilidade)
- [ ] Testes unitÃ¡rios verificam parsing do array `words`
- [ ] Google provider nÃ£o Ã© afetado (nÃ£o suporta word-level â€” ignora graciosamente)

---

### ğŸ”µ US-015.3: Implementar ServiÃ§o de DiarizaÃ§Ã£o via LLM

**Como** sistema de processamento de aulas
**Quero** passar a transcriÃ§Ã£o word-level para um LLM que identifica professor vs aluno
**Para** gerar um SRT enriquecido com identificaÃ§Ã£o de falantes

#### Detalhes TÃ©cnicos

O serviÃ§o recebe o array de `TranscriptionWord[]` e usa um LLM (default: Gemini Flash) para:
1. Agrupar palavras em frases/turnos de fala
2. Classificar cada turno como `[PROFESSOR]` ou `[ALUNO]`
3. Gerar saÃ­da em formato SRT com speaker labels e timestamps

#### ImplementaÃ§Ã£o

**Novo arquivo:**
- `ressoa-backend/src/modules/stt/services/diarization.service.ts`

**Prompt de DiarizaÃ§Ã£o:**

```typescript
const DIARIZATION_PROMPT = `VocÃª Ã© um especialista em anÃ¡lise de transcriÃ§Ãµes de aulas escolares brasileiras.

ENTRADA: TranscriÃ§Ã£o com timestamps por palavra de uma aula escolar.

TAREFA:
1. Agrupe as palavras em frases/turnos de fala naturais
2. Identifique quem estÃ¡ falando: PROFESSOR ou ALUNO
3. Formate a saÃ­da em SRT com labels de speaker

REGRAS DE IDENTIFICAÃ‡ÃƒO:
- PROFESSOR: Explica conceitos, faz perguntas didÃ¡ticas, dÃ¡ instruÃ§Ãµes, usa linguagem formal, cita termos tÃ©cnicos/BNCC
- ALUNO: Responde perguntas, faz perguntas de dÃºvida, usa linguagem informal, respostas curtas
- Na DÃšVIDA, marque como PROFESSOR (professores falam ~70-80% do tempo em aulas expositivas)
- MudanÃ§as de speaker geralmente coincidem com pausas (gaps > 0.5s entre palavras)

FORMATO DE SAÃDA (SRT estrito):
- Cada bloco: nÃºmero sequencial, timestamp (HH:MM:SS,mmm --> HH:MM:SS,mmm), [SPEAKER] texto
- Agrupe palavras consecutivas do mesmo speaker em um bloco (mÃ¡x 3 linhas por bloco)
- Use vÃ­rgula (nÃ£o ponto) como separador de milissegundos no timestamp SRT

Responda APENAS com o SRT, sem explicaÃ§Ãµes.`;
```

**Fluxo do ServiÃ§o:**

```typescript
@Injectable()
export class DiarizationService {
  constructor(
    private readonly llmRouter: LLMRouterService,
    private readonly config: ProvidersConfigService,
  ) {}

  async diarize(words: TranscriptionWord[], disciplina?: string): Promise<DiarizationResult> {
    const provider = this.config.getDiarizationLLMProvider(); // NOVO config
    const wordText = this.formatWordsForLLM(words);

    const response = await this.llmRouter.complete({
      provider,
      prompt: DIARIZATION_PROMPT,
      input: wordText,
      temperature: 0.1, // Baixa criatividade para classificaÃ§Ã£o
      maxTokens: 4096,
    });

    return {
      srt: response.text,
      provider,
      custo_usd: response.cost,
      tempo_processamento_ms: response.duration,
    };
  }

  private formatWordsForLLM(words: TranscriptionWord[]): string {
    return words
      .map(w => `[${this.formatTime(w.start)}] ${w.word}`)
      .join('\n');
  }
}
```

#### CritÃ©rios de AceitaÃ§Ã£o

- [ ] ServiÃ§o `DiarizationService` criado no mÃ³dulo STT
- [ ] Recebe `TranscriptionWord[]` e retorna SRT com speaker labels
- [ ] Usa LLM Router existente para chamada ao provider configurado
- [ ] Provider de diarizaÃ§Ã£o Ã© configurÃ¡vel (default: Gemini Flash)
- [ ] Prompt identifica corretamente `[PROFESSOR]` e `[ALUNO]` em cenÃ¡rios tÃ­picos
- [ ] Output Ã© SRT vÃ¡lido (parseable por bibliotecas padrÃ£o)
- [ ] Custo e tempo de processamento sÃ£o rastreados no resultado
- [ ] Fallback: se LLM falhar, retorna SRT sem labels (apenas timestamps + texto)
- [ ] Timeout de 60s para a chamada LLM (aulas longas geram input grande)
- [ ] Log estruturado com mÃ©tricas de diarizaÃ§Ã£o (segmentos professor/aluno)

---

### ğŸ”µ US-015.4: ConfiguraÃ§Ã£o do Provider de DiarizaÃ§Ã£o

**Como** administrador do sistema
**Quero** configurar qual LLM Ã© usado para diarizaÃ§Ã£o
**Para** controlar custo e qualidade da identificaÃ§Ã£o de speakers

#### ImplementaÃ§Ã£o

**Arquivo a modificar:**
- `ressoa-backend/src/config/env.ts` (ou equivalente de configuraÃ§Ã£o de providers)

**Novas variÃ¡veis de ambiente:**

```env
# Diarization LLM Provider
DIARIZATION_LLM_PROVIDER=GEMINI_FLASH       # GEMINI_FLASH | CLAUDE | OPENAI
DIARIZATION_ENABLED=true                      # true | false (feature flag)
DIARIZATION_FALLBACK_PROVIDER=OPENAI          # Fallback se primÃ¡rio falhar
```

**IntegraÃ§Ã£o com ProvidersConfigService:**

```typescript
getDiarizationLLMProvider(): string {
  return this.configService.get('DIARIZATION_LLM_PROVIDER', 'GEMINI_FLASH');
}

isDiarizationEnabled(): boolean {
  return this.configService.get('DIARIZATION_ENABLED', 'true') === 'true';
}

getDiarizationFallbackProvider(): string {
  return this.configService.get('DIARIZATION_FALLBACK_PROVIDER', 'OPENAI');
}
```

#### CritÃ©rios de AceitaÃ§Ã£o

- [ ] VariÃ¡veis `DIARIZATION_LLM_PROVIDER`, `DIARIZATION_ENABLED`, `DIARIZATION_FALLBACK_PROVIDER` adicionadas ao `.env.example`
- [ ] `ProvidersConfigService` expÃµe mÃ©todos para acessar configuraÃ§Ã£o de diarizaÃ§Ã£o
- [ ] ValidaÃ§Ã£o: provider configurado deve existir no LLM Router
- [ ] Feature flag `DIARIZATION_ENABLED` permite desabilitar diarizaÃ§Ã£o (salva transcriÃ§Ã£o sem speakers)
- [ ] DocumentaÃ§Ã£o das variÃ¡veis no `.env.example`

---

### ğŸ”µ US-015.5: Integrar Pipeline Completo (STT â†’ DiarizaÃ§Ã£o â†’ Salvar)

**Como** professor que faz upload de Ã¡udio
**Quero** que minha transcriÃ§Ã£o seja automaticamente enriquecida com diarizaÃ§Ã£o
**Para** que as anÃ¡lises pedagÃ³gicas saibam quem disse o quÃª

#### Detalhes TÃ©cnicos

Integrar as stories anteriores no fluxo existente de processamento de aulas. O pipeline roda no Bull queue worker, de forma assÃ­ncrona.

#### Fluxo Atualizado

```
Audio Upload â†’ Bull Queue â†’ STT (com prompt + word timestamps)
                                    â†“
                            DiarizationService (LLM)
                                    â†“
                            Salvar Transcricao {
                              texto: SRT enriquecido,
                              metadata_json: {
                                ...existente,
                                diarization_provider: "GEMINI_FLASH",
                                diarization_cost_usd: 0.008,
                                diarization_processing_ms: 3200,
                                word_count: 1847,
                                speaker_stats: {
                                  professor_segments: 42,
                                  aluno_segments: 18,
                                  professor_time_pct: 74.2
                                },
                                stt_prompt_used: "matematica",
                                has_diarization: true
                              }
                            }
                                    â†“
                            Status: TRANSCRITA â†’ (pipeline anÃ¡lise continua)
```

#### CritÃ©rios de AceitaÃ§Ã£o

- [ ] ApÃ³s transcriÃ§Ã£o STT, diarizaÃ§Ã£o Ã© executada automaticamente (se `DIARIZATION_ENABLED=true`)
- [ ] Campo `texto` da `Transcricao` salvo em formato SRT com speaker labels
- [ ] `metadata_json` inclui mÃ©tricas de diarizaÃ§Ã£o (provider, custo, stats de speakers)
- [ ] Se diarizaÃ§Ã£o falhar, transcriÃ§Ã£o Ã© salva em SRT sem labels (fallback gracioso â€” nÃ£o bloqueia pipeline)
- [ ] Se `DIARIZATION_ENABLED=false`, transcriÃ§Ã£o salva em formato SRT simples (com timestamps, sem speakers)
- [ ] Custo total (STT + diarizaÃ§Ã£o) rastreado corretamente
- [ ] Tempo total de processamento logado (STT + diarizaÃ§Ã£o separados)
- [ ] Status da aula transiciona corretamente: `AGUARDANDO_TRANSCRICAO â†’ TRANSCRITA`
- [ ] Pipeline de anÃ¡lise downstream (5 prompts) recebe e interpreta SRT corretamente

---

### ğŸ”µ US-015.6: Atualizar Prompts de AnÃ¡lise para Consumir SRT

**Como** pipeline de anÃ¡lise pedagÃ³gica
**Quero** interpretar transcriÃ§Ãµes em formato SRT com speaker labels
**Para** gerar anÃ¡lises que diferenciam falas do professor e dos alunos

#### Detalhes TÃ©cnicos

Os 5 prompts do pipeline de anÃ¡lise (Cobertura â†’ Qualitativa â†’ RelatÃ³rio â†’ ExercÃ­cios â†’ Alertas) precisam ser atualizados para:
1. Reconhecer o formato SRT de entrada
2. Usar as labels `[PROFESSOR]` e `[ALUNO]` na anÃ¡lise
3. Aproveitar timestamps para contextualizar momentos da aula

#### CritÃ©rios de AceitaÃ§Ã£o

- [ ] Prompts de anÃ¡lise reconhecem e interpretam formato SRT
- [ ] AnÃ¡lise diferencia contribuiÃ§Ãµes do professor vs alunos
- [ ] Timestamps sÃ£o usados para referenciar momentos especÃ­ficos da aula
- [ ] Compatibilidade mantida: se receber texto puro (legado), ainda funciona
- [ ] RelatÃ³rios gerados incluem insights de participaÃ§Ã£o (% fala professor/aluno)

---

## ğŸ“Š Estimativa de Custo por Aula

| Etapa | Provider | Custo Estimado |
|-------|----------|----------------|
| STT (45min Ã¡udio) | Groq Whisper Large v3 Turbo | ~$0.03 |
| DiarizaÃ§Ã£o (~2000 palavras) | Gemini Flash | ~$0.008 |
| **Total adicional** | | **~$0.01** (apenas diarizaÃ§Ã£o Ã© custo novo) |

**Impacto mensal (100 aulas/escola):** ~R$6/mÃªs adicional â€” desprezÃ­vel vs receita de R$1.200/mÃªs.

---

## âš ï¸ Riscos e MitigaÃ§Ãµes

| Risco | Probabilidade | Impacto | MitigaÃ§Ã£o |
|-------|--------------|---------|-----------|
| LLM erra diarizaÃ§Ã£o (professor como aluno) | MÃ©dia | MÃ©dio | Default para PROFESSOR em caso de dÃºvida; threshold de confianÃ§a; feedback loop |
| Ãudio com muitos alunos falando simultaneamente | Alta | Baixo | LLM marca como `[ALUNO]` genÃ©rico â€” suficiente para anÃ¡lise |
| Prompt STT degrada transcriÃ§Ã£o em vez de melhorar | Baixa | MÃ©dio | A/B testing com e sem prompt; rollback via config |
| SRT quebra pipeline de anÃ¡lise existente | Baixa | Alto | Compatibilidade backward: prompts aceitam texto puro ou SRT |
| Custo Gemini Flash aumenta | Baixa | Baixo | Provider configurÃ¡vel â€” troca para outro LLM sem code change |

---

## ğŸ”— DependÃªncias

- **EPIC-001** (GestÃ£o de Cadastros) â€” NÃ£o bloqueador direto
- **Story 14.3** (Gemini Flash Provider) â€” âœ… JÃ¡ implementada
- **Story 14.4** (Provider Router) â€” âœ… JÃ¡ implementada
- **Pipeline de AnÃ¡lise** (5 prompts) â€” US-015.6 atualiza os prompts

---

## ğŸ“ˆ MÃ©tricas de Sucesso

| MÃ©trica | Baseline (Atual) | Target |
|---------|------------------|--------|
| AcurÃ¡cia de termos BNCC na transcriÃ§Ã£o | ~85% (estimativa) | >95% |
| AcurÃ¡cia diarizaÃ§Ã£o professor/aluno | N/A | >90% |
| Custo adicional por aula | $0 | <$0.02 |
| Tempo adicional de processamento | 0s | <15s (diarizaÃ§Ã£o) |
| Qualidade da anÃ¡lise pedagÃ³gica (NPS) | Baseline a medir | +10 pontos |
| Taxa de aprovaÃ§Ã£o de relatÃ³rios | Baseline a medir | +15% |

---

## ğŸ“‹ Ordem de ImplementaÃ§Ã£o

```
US-015.1 (Prompt STT) â”€â”€â”
                         â”œâ”€â”€â†’ US-015.3 (DiarizaÃ§Ã£o LLM) â”€â”€â†’ US-015.5 (IntegraÃ§Ã£o Pipeline) â”€â”€â†’ US-015.6 (Atualizar Prompts AnÃ¡lise)
US-015.2 (Word Timestamps)â”˜                                        â–²
                                                                   â”‚
US-015.4 (Config Provider) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ParalelizÃ¡veis:** US-015.1 + US-015.2 (independentes), US-015.4 (independente)
**Sequenciais:** US-015.3 depende de US-015.2 â†’ US-015.5 depende de US-015.3 + US-015.4 â†’ US-015.6 depende de US-015.5
